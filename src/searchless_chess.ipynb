{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcWXEQI7Ws2l"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import chess\n",
        "import chess.svg\n",
        "from jax import random as jrandom\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUuSZBYyWvbf"
      },
      "outputs": [],
      "source": [
        "from searchless_chess.src import tokenizer\n",
        "from searchless_chess.src import training_utils\n",
        "from searchless_chess.src import transformer\n",
        "from searchless_chess.src import utils\n",
        "from searchless_chess.src.engines import engine\n",
        "from searchless_chess.src.engines import neural_engines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8w6FnstXMr4"
      },
      "outputs": [],
      "source": [
        "# @title Create the predictor.\n",
        "\n",
        "policy = 'action_value'\n",
        "num_return_buckets = 128\n",
        "\n",
        "match policy:\n",
        "  case 'action_value':\n",
        "    output_size = num_return_buckets\n",
        "  case 'behavioral_cloning':\n",
        "    output_size = utils.NUM_ACTIONS\n",
        "  case 'state_value':\n",
        "    output_size = num_return_buckets\n",
        "  case _:\n",
        "    raise ValueError(f'Unknown policy: {policy}')\n",
        "\n",
        "predictor_config = transformer.TransformerConfig(\n",
        "    vocab_size=utils.NUM_ACTIONS,\n",
        "    output_size=output_size,\n",
        "    pos_encodings=transformer.PositionalEncodings.LEARNED,\n",
        "    max_sequence_length=tokenizer.SEQUENCE_LENGTH + 2,\n",
        "    num_heads=4,\n",
        "    num_layers=4,\n",
        "    embedding_dim=64,\n",
        "    apply_post_ln=True,\n",
        "    apply_qk_layernorm=False,\n",
        "    use_causal_mask=False,\n",
        ")\n",
        "\n",
        "predictor = transformer.build_transformer_predictor(config=predictor_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZugSBZLXJxn"
      },
      "outputs": [],
      "source": [
        "# @title Load the predictor parameters\n",
        "\n",
        "checkpoint_dir = os.path.join(\n",
        "    os.getcwd(),\n",
        "    f'../checkpoints/local/{policy}/',\n",
        ")\n",
        "dummy_params = predictor.initial_params(\n",
        "    rng=jrandom.PRNGKey(0),\n",
        "    targets=np.zeros((1, 1), dtype=np.uint32),\n",
        ")\n",
        "params = training_utils.load_parameters(\n",
        "    checkpoint_dir=checkpoint_dir,\n",
        "    params=dummy_params,\n",
        "    use_ema_params=True,\n",
        "    step=-1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYRlpAbPZCIs"
      },
      "outputs": [],
      "source": [
        "# @title Create the engine\n",
        "\n",
        "predict_fn = neural_engines.wrap_predict_fn(predictor, params, batch_size=1)\n",
        "_, return_buckets_values = utils.get_uniform_buckets_edges_values(\n",
        "    num_return_buckets\n",
        ")\n",
        "\n",
        "neural_engine = neural_engines.ENGINE_FROM_POLICY[policy](\n",
        "    return_buckets_values=return_buckets_values,\n",
        "    predict_fn=predict_fn,\n",
        "    temperature=0.005,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QiE6-8A8ZZl5"
      },
      "outputs": [],
      "source": [
        "# @title Play a move with the agent\n",
        "\n",
        "board = chess.Board()\n",
        "best_move = neural_engine.play(board)\n",
        "print(f'Best move: {best_move}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCL1f--1ab6w"
      },
      "outputs": [],
      "source": [
        "# @title Compute the win percentages for all legal moves\n",
        "\n",
        "board = chess.Board()\n",
        "results = neural_engine.analyse(board)\n",
        "buckets_log_probs = results['log_probs']\n",
        "\n",
        "# Compute the expected return.\n",
        "win_probs = np.inner(np.exp(buckets_log_probs), return_buckets_values)\n",
        "sorted_legal_moves = engine.get_ordered_legal_moves(board)\n",
        "\n",
        "print(board.fen())\n",
        "print(f'Win percentages:')\n",
        "for i in np.argsort(win_probs)[::-1]:\n",
        "  print(f'  {sorted_legal_moves[i].uci()} -\u003e {100*win_probs[i]:.1f}%')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "//third_party/deepmind/searchless_chess/src:searchless_chess",
        "kind": "private"
      },
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
